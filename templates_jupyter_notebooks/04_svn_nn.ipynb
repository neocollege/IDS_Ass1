{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98faa7c52117b08c",
   "metadata": {},
   "source": [
    "# Support Vector Machines and Neural Networks\n",
    "We strongly recommend consulting the related exercises' jupyter notebooks and the referenced URLs when working on this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b7f88e5b40f35b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T10:47:09.852854Z",
     "start_time": "2024-10-28T10:47:09.844800Z"
    }
   },
   "outputs": [],
   "source": [
    "# set random seeds\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# Import Pandas and NumPy functionality for editing data\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "# Importing IPython display for visualizing intermediate results in the notebook\n",
    "from IPython.display import display\n",
    "\n",
    "# data preparation\n",
    "# classifiers\n",
    "# evaluation\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f32537e796b5e2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T10:47:09.920376Z",
     "start_time": "2024-10-28T10:47:09.910513Z"
    }
   },
   "outputs": [],
   "source": [
    "# general variables that may help you in the tasks\n",
    "numeric_features = [\"age\", \"trestbps\", \"chol\", \"thalch\", \"oldpeak\"]\n",
    "colors_target = {\"healthy heart\": \"b\", \"heart condition\": \"r\", 0: \"b\", 1: \"r\", 2: \"g\", 3: \"y\", 4: \"m\"}\n",
    "markers_target = {\"healthy heart\": \"o\", \"heart condition\": \"^\", 2: \"d\", 3: \"s\", 4: \"v\", 0: \"o\", 1: \"^\", }\n",
    "colors = [\"blue\", \"red\", \"green\", \"yellow\", \"cyan\"]\n",
    "markers = [\"o\", \"^\", \"d\", \"s\", \"v\"]\n",
    "\n",
    "### we recommend creating two datasets for the SVM and NN classifiers both with a column called \"target\" containing the target values. This allows you to make use of the following functions for both classifiers. You don\"t need to use these functions, but they might appear useful to you.\n",
    "### for the full data you use on the neural network, we recommend just renaming the column called \"num\" (df.rename(columns={\"num\": \"target\"}) \n",
    "### in the binary classifiers this target column should contain the values \"healthy heart\" and \"heart condition\" \n",
    "target_name = \"target\"\n",
    "target = [target_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6c4f998c9a7fe0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T10:47:09.967220Z",
     "start_time": "2024-10-28T10:47:09.935310Z"
    }
   },
   "outputs": [],
   "source": [
    "###### Potentially useful functions ######\n",
    "\n",
    "# Pairplot for numeric features\n",
    "def create_pairplot(data: pd.DataFrame, features: list = numeric_features, target_name: str = target_name,\n",
    "                    markers: list = markers, name: str = None):\n",
    "    markers = markers[:len(data[target_name].unique())]\n",
    "    pairplot = sns.pairplot(data[features + [target_name]], hue=target_name, diag_kind=\"hist\", markers=markers)\n",
    "    if name:\n",
    "        pairplot.fig.suptitle(f\"Pairplot for {name}\")\n",
    "        pairplot.savefig(f\"pairplot_{name}.png\")\n",
    "\n",
    "    display(pairplot)\n",
    "\n",
    "\n",
    "# Bar Chart for values in selected column\n",
    "def create_barchart_selected_column(training_data: pd.DataFrame, test_data: pd.DataFrame, column_name: str,\n",
    "                                    name: str = None, relative_values: bool = True):\n",
    "    for data_name, data in zip(('Training Data', 'Test Data'), (training_data, test_data)):\n",
    "\n",
    "        class_counts = data[column_name].value_counts(normalize=relative_values)\n",
    "        class_counts = class_counts.round(2)\n",
    "\n",
    "        ax = class_counts.plot(kind=\"bar\")\n",
    "\n",
    "        for p in ax.patches:\n",
    "            ax.annotate(f\"{p.get_height()}\",\n",
    "                        (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                        ha=\"center\", va=\"center\",\n",
    "                        xytext=(0, 10),\n",
    "                        textcoords=\"offset points\")\n",
    "\n",
    "        plt.xlabel(column_name)\n",
    "        plt.ylabel(\"Frequency\")\n",
    "        plt.title(f\"Frequency of Instances per {column_name} in  {data_name}\")\n",
    "\n",
    "        # make xaxis labels horizontal\n",
    "        plt.xticks(rotation=0)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        if name:\n",
    "            plt.savefig(f\"hist_{name}_{data_name}.png\")\n",
    "        else:\n",
    "            plt.savefig(f\"hist_{data_name}.png\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "## Create 3D scatter plot\n",
    "def create_3d_scatter(data: pd.DataFrame, x_column: str, y_column: str, z_column: str, target_name: str = target_name,\n",
    "                      colors: dict = colors_target, markers: dict = markers_target, name: str = None):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "    # Plot the 3D scatter plot with different colors and markers\n",
    "    for target_class in data[target_name].unique():\n",
    "        class_data = data[data[target_name] == target_class]\n",
    "        ax.scatter(class_data[x_column], class_data[y_column], class_data[z_column],\n",
    "                   c=colors[target_class], marker=markers[target_class], label=target_class)\n",
    "\n",
    "    # Set labels\n",
    "    ax.set_xlabel(x_column)\n",
    "    ax.set_ylabel(y_column)\n",
    "    ax.set_zlabel(z_column)\n",
    "\n",
    "    # Set title\n",
    "    ax.set_title(f\"3D Scatter Plot: {x_column}, {y_column}, {z_column}\")\n",
    "\n",
    "    if name:\n",
    "        plt.savefig(f\"3d_scatter_{name}_{x_column}_{y_column}_{z_column}.png\")\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "## results grid search\n",
    "def compare_results_grid_search(grid_object, run_name: str):\n",
    "    results = pd.DataFrame(grid_object.cv_results_)\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    colors_setting = {\"linear\": \"r\", \"rbf\": \"y\", \"sigmoid\": \"g\", \"poly\": \"b\"}\n",
    "    markers_setting = {\"linear\": \"o\", \"rbf\": \"^\", \"sigmoid\": \"s\", \"poly\": \"x\"}\n",
    "\n",
    "    for kernel in results[\"param_kernel\"].unique():\n",
    "        kernel_data = results[results[\"param_kernel\"] == kernel]\n",
    "        plt.scatter(kernel_data[\"param_C\"], kernel_data[\"mean_test_score\"],\n",
    "                    label=kernel, marker=markers_setting[kernel], color=colors_setting[kernel])\n",
    "\n",
    "    plt.xlabel(\"Regularization Parameter (C)\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Grid Search Results\")\n",
    "    plt.legend(title=\"Kernel\")\n",
    "\n",
    "    if run_name:\n",
    "        plt.savefig(f\"grid_search_results_{run_name}.png\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb53857c7189ef1",
   "metadata": {},
   "source": [
    "### SVMs: Load, prepare and visualize data\n",
    "We recommend resetting the index and dropping the _id_ column.\n",
    "To help you set up a sensible data structure, we kept the cells with comments on what we did here to create a possible solution to the first subtask. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d3db06fe87a567c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T10:47:10.954347Z",
     "start_time": "2024-10-28T10:47:10.948335Z"
    }
   },
   "outputs": [],
   "source": [
    "# load the data \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1204aa6195e4e7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T10:47:10.991335Z",
     "start_time": "2024-10-28T10:47:10.984228Z"
    }
   },
   "outputs": [],
   "source": [
    "# prepare the full data sets for binary classifier & drop old target\n",
    "\n",
    "\n",
    "# drop num column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa921ec3b0ff33d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T10:47:11.021984Z",
     "start_time": "2024-10-28T10:47:11.015935Z"
    }
   },
   "outputs": [],
   "source": [
    "# prepare the full data sets for nn classifier & rename target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d127aa3a0d59796c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T10:47:11.174205Z",
     "start_time": "2024-10-28T10:47:11.165739Z"
    }
   },
   "outputs": [],
   "source": [
    "# create new dataframes with only the descriptive feature matrices (X) and the target feature vectors (y) for both the training and test data. The descriptive feature matrix is the same for both the SVM and the NN classifier.\n",
    "\n",
    "# descr. feature matrices (train & test)\n",
    "\n",
    "\n",
    "# target feature vectors binary classifier\n",
    "\n",
    "# target feature vectors severity classifier (Neural Network)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935a46359e20e32f",
   "metadata": {},
   "source": [
    "### Data Exploration & Visualization\n",
    "#### Severity Classification: Distribution of Heart Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79e1d8924452690",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T10:47:11.262539Z",
     "start_time": "2024-10-28T10:47:11.240994Z"
    }
   },
   "outputs": [],
   "source": [
    "# For those among you who are curious: A function to create a 3D scatterplot depicting the hyperplane ;)\n",
    "\n",
    "def plot_3d_hyperplane(svm_classifier, training_data: pd.DataFrame, target_name: str, colors=colors_target,\n",
    "                       markers=markers_target, name: str = None):\n",
    "    # Extract the coefficients and intercept\n",
    "    weights = svm_classifier.coef_[0]\n",
    "    intercept = svm_classifier.intercept_[0]\n",
    "    feature_order = svm_classifier.feature_names_in_\n",
    "\n",
    "    # Create a mesh grid for the 3D space\n",
    "    xx, yy = np.meshgrid(\n",
    "        np.linspace(training_data[feature_order[0]].min(), training_data[feature_order[0]].max(), 50),\n",
    "        np.linspace(training_data[feature_order[1]].min(), training_data[feature_order[1]].max(), 50))\n",
    "\n",
    "    # Calculate the decision boundary (hyperplane)\n",
    "    zz = (-weights[0] * xx - weights[1] * yy - intercept) / weights[2]\n",
    "\n",
    "    # Plot the 3D scatter plot and the hyperplane\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "    # Plot the 3D scatter plot with different colors and markers\n",
    "    for target_class in training_data[target_name].unique():\n",
    "        class_data = training_data[training_data[target_name] == target_class]\n",
    "        ax.scatter(class_data[feature_order[0]], class_data[feature_order[1]], class_data[feature_order[2]],\n",
    "                   c=colors[target_class], marker=markers[target_class], label=target_class)\n",
    "\n",
    "    # Plot the hyperplane\n",
    "    ax.plot_surface(xx, yy, zz, color=\"yellow\", alpha=0.2)\n",
    "\n",
    "    # Set labels\n",
    "    ax.set_xlabel(feature_order[0])\n",
    "    ax.set_ylabel(feature_order[1])\n",
    "    ax.set_zlabel(feature_order[2])\n",
    "\n",
    "    # Set title\n",
    "    ax.set_title(\n",
    "        f\"3D Scatter Plot with SVM Hyperplane, {feature_order[0]}, {feature_order[1]}, {feature_order[2]}\")\n",
    "\n",
    "    # Add legend\n",
    "    ax.legend()\n",
    "    if name:\n",
    "        plt.savefig(f\"3d_scatter_{name}_plane.png\")\n",
    "    else:\n",
    "        pass\n",
    "    # Show plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4dc282e3b2ff2d",
   "metadata": {},
   "source": [
    "#### Severity Classifier Target Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a590ab6a72b7c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T10:47:11.300144Z",
     "start_time": "2024-10-28T10:47:11.292798Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "60746afd4db8af4a",
   "metadata": {},
   "source": [
    "#### Binary Classifier: 3D and 2D Feature Visualization\n",
    "Select three features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b578619ac1bd7d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T10:47:11.338804Z",
     "start_time": "2024-10-28T10:47:11.329489Z"
    }
   },
   "outputs": [],
   "source": [
    "selected_features = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a782d5a3b95082e8",
   "metadata": {},
   "source": [
    "\n",
    "### Grid search for configuration\n",
    "Train binary classifiers using only the three selected features as descriptive features.\n",
    "\n",
    "For this question, we recommend taking a look at the method \"cv_results\" of the grid search object: https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48102261ec640de1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T10:47:11.444584Z",
     "start_time": "2024-10-28T10:47:11.438218Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4447af33937f5663",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T10:47:11.483225Z",
     "start_time": "2024-10-28T10:47:11.472914Z"
    }
   },
   "outputs": [],
   "source": [
    "grid_params_selected_features = {\n",
    "    \"C\": [0.1, 10, 50, 100, 500],\n",
    "    \"kernel\": [\"linear\", \"rbf\", \"poly\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66490575a9e64725",
   "metadata": {},
   "source": [
    "### Baseline Models\n",
    "Both classifier types are trained using all features.\n",
    "\n",
    "#### SVMs: Base Binary Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701233c365393acb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T10:47:11.566450Z",
     "start_time": "2024-10-28T10:47:11.560358Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df8e418f7622c660",
   "metadata": {},
   "source": [
    "#### Neural Network: Base Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493cef03812dd967",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T10:47:11.605550Z",
     "start_time": "2024-10-28T10:47:11.598657Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b278f057d7cf4e2",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "821c3949060840c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T10:47:11.696159Z",
     "start_time": "2024-10-28T10:47:11.675036Z"
    }
   },
   "outputs": [],
   "source": [
    "def deviation_mean(training_data: pd.DataFrame, test_data: pd.DataFrame, features_to_transform: list = None,\n",
    "                   target_name: str = target_name) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Pass training and test data as well as a list of features you want to transform. Function returns test and training data lifted to the higher dimension by dividing each of the passed feature names' values by the trainings data's mean.\"\"\"\n",
    "\n",
    "    if features_to_transform is None:\n",
    "        features_to_transform = training_data.columns.drop(target_name)\n",
    "\n",
    "    ## add you code here\n",
    "    ...\n",
    "\n",
    "    return training_data_transformed, test_data_transformed\n",
    "\n",
    "\n",
    "def scale_zero(training_data: pd.DataFrame, test_data: pd.DataFrame, features_to_transform: list = None,\n",
    "               target_name: str = target_name) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Pass training data and test data as well as a list of features you want to transform. Function returns dataframes containing the transformed test and training data. In the transformed dataframes the values of each of the passed feature names are scaled around zero.\"\"\"\n",
    "    if features_to_transform is None:\n",
    "        features_to_transform = training_data.columns.drop(target_name)\n",
    "\n",
    "    ## add you code here\n",
    "    ...\n",
    "\n",
    "    return training_data_transformed, test_data_transformed\n",
    "\n",
    "\n",
    "def normalize_features(training_data: pd.DataFrame, test_data: pd.DataFrame, features_to_transform: list = None,\n",
    "                       target_name: str = target_name) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Pass training data and test data as well as a list of features you want to transform. Function returns dataframes containing the transformed test and training data. In the transformed dataframes the values of each of the passed features are normalized according to the value's ranges.\"\"\"\n",
    "\n",
    "    if features_to_transform is None:\n",
    "        features_to_transform = training_data.columns.drop(target_name)\n",
    "\n",
    "    ## add you code here\n",
    "    ...\n",
    "\n",
    "    return training_data_transformed, test_data_transformed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73257143ac538b13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T10:47:11.738987Z",
     "start_time": "2024-10-28T10:47:11.732602Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2fe7b43368df369",
   "metadata": {},
   "source": [
    "### Neural Network Structure\n",
    "First, only consider the training data. Then, in the next subtask, consider the test data as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61335690ca0bd7ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T10:47:11.775637Z",
     "start_time": "2024-10-28T10:47:11.768489Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "720f3d751bc86f3b",
   "metadata": {},
   "source": [
    "### Good SVM Classifier\n",
    "Perform some educated trial and error to try and find a good SVM classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe935319e232fc9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T10:47:11.879611Z",
     "start_time": "2024-10-28T10:47:11.874175Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-ids",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
